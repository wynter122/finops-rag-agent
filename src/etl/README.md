# ETL (Extract, Transform, Load) ëª¨ë“ˆ

AWS SageMaker ë¹„ìš© ë¶„ì„ì„ ìœ„í•œ ETL íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤. Redshift CUR ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

## ğŸ“ ëª¨ë“ˆ êµ¬ì¡°

```
src/etl/
â”œâ”€â”€ __init__.py      # ëª¨ë“ˆ ì´ˆê¸°í™” ë° API ë…¸ì¶œ
â”œâ”€â”€ extract.py       # Redshift ë°ì´í„° ì¶”ì¶œ
â”œâ”€â”€ transform.py     # ë°ì´í„° ë³€í™˜ ë° ì§‘ê³„
â”œâ”€â”€ clean.py         # LLM ì •ê·œí™” (ì„ íƒì‚¬í•­)
â”œâ”€â”€ store.py         # ë°ì´í„° ì €ì¥
â”œâ”€â”€ runner.py        # ETL ì‹¤í–‰ê¸°
â””â”€â”€ README.md        
```

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 0. ì‚¬ì „ ì¤€ë¹„

#### ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
uv sync
```

#### ë””ë ‰í† ë¦¬ ìƒì„±
```bash
# ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p data/raw data/processed
```

#### í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„± ë° ì„¤ì •
cp .env.example .env  # ì˜ˆì‹œ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°
# ë˜ëŠ” ì§ì ‘ .env íŒŒì¼ ìƒì„±
```

### 1. ê¸°ë³¸ ì‹¤í–‰

#### ë©”ì¸ ì‹¤í–‰ íŒŒì¼ ì‚¬ìš© (ê¶Œì¥)
```bash
python -m src.run_etl --billing-ym 202508 --accounts 123456789101,112233445566
```

#### ì§ì ‘ runner.py ì‹¤í–‰
```bash
python src/etl/runner.py --billing-ym 202508 --accounts 123456789101,112233445566
```

### 2. íŒŒë¼ë¯¸í„° ì„¤ëª…

#### í•„ìˆ˜ íŒŒë¼ë¯¸í„°
- `--billing-ym`: ì²­êµ¬ ì—°ì›”
  ```bash
  --billing-ym 202508    # 2025ë…„ 8ì›”
  --billing-ym 2025-08   # ë™ì¼ (í•˜ì´í”ˆ í¬í•¨ ê°€ëŠ¥)
  ```

#### ì„ íƒ íŒŒë¼ë¯¸í„°
- `--accounts`: AWS ê³„ì • ID ëª©ë¡
  ```bash
  --accounts 123456789101,112233445566,987654321987
  ```

- `--contract`: ê³„ì•½ ID ì‚¬ìš© (contracts.jsonì—ì„œ ì •ì˜)
  ```bash
  --contract cloud-radar-prod
  ```

- `--input-csv`: ë¡œì»¬ CSV íŒŒì¼ ì‚¬ìš© (Redshift ëŒ€ì‹ )
  ```bash
  --input-csv data/raw/sagemaker_cur_sample.csv
  ```

- `--limit`: Redshift ì¿¼ë¦¬ ì œí•œ (ë””ë²„ê·¸ìš©)
  ```bash
  --limit 1000
  ```

- `--list-contracts`: ì‚¬ìš© ê°€ëŠ¥í•œ ê³„ì•½ ëª©ë¡ ì¶œë ¥
  ```bash
  --list-contracts
  ```

### 3. ì‹¤í–‰ ì˜ˆì‹œ

#### Redshiftì—ì„œ ì§ì ‘ ì¶”ì¶œ
```bash
# ê¸°ë³¸ ì‹¤í–‰
python -m src.run_etl --billing-ym 202508 --accounts 123456789101,112233445566

# ê³„ì•½ ì‚¬ìš©
python -m src.run_etl --billing-ym 202508 --contract cloud-radar-prod

# ë””ë²„ê·¸ìš© ì œí•œ
python -m src.run_etl --billing-ym 202508 --accounts 123456789101 --limit 1000
```

#### ë¡œì»¬ CSV íŒŒì¼ ì‚¬ìš©
```bash
python -m src.run_etl --billing-ym 202508 \
  --accounts 123456789101,112233445566 \
  --input-csv data/raw/sagemaker_cur_sample.csv
```

#### ê³„ì•½ ëª©ë¡ í™•ì¸
```bash
python -m src.run_etl --list-contracts
```

## ğŸ”§ ëª¨ë“ˆë³„ ê¸°ëŠ¥

### extract.py - ë°ì´í„° ì¶”ì¶œ

Redshiftì—ì„œ SageMaker CUR ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

#### ì£¼ìš” í•¨ìˆ˜
- `extract_cur_from_redshift()`: Redshiftì—ì„œ CUR ë°ì´í„° ì¶”ì¶œ
- `load_raw_from_csv()`: ë¡œì»¬ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
- `save_raw()`: ì›ì‹œ ë°ì´í„°ë¥¼ Parquet/CSVë¡œ ì €ì¥

#### ì¶”ì¶œë˜ëŠ” ì»¬ëŸ¼
- ì²­êµ¬ ì •ë³´: `bill_billingperiodstartdate`, `bill_billingperiodenddate`, `billing_ym`
- ê³„ì •/ë¦¬ì†ŒìŠ¤: `lineitem_usageaccountid`, `lineitem_resourceid`
- ì‚¬ìš©ëŸ‰/ë¹„ìš©: `lineitem_usageamount`, `lineitem_unblendedcost`, `lineitem_blendedcost`
- ì„œë¹„ìŠ¤ ì •ë³´: `lineitem_productcode`, `lineitem_usagetype`, `lineitem_operation`
- ì œí’ˆ ì •ë³´: `product_productname`, `product_instancetype`, `product_region`
- íƒœê·¸ ì •ë³´: `usertag0` ~ `usertag9`

### transform.py - ë°ì´í„° ë³€í™˜

CUR ë°ì´í„°ë¥¼ ë¶„ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ì§‘ê³„í•©ë‹ˆë‹¤.

#### ìƒì„±ë˜ëŠ” íŒŒìƒ ì»¬ëŸ¼
- `is_endpoint`: Endpoint ê´€ë ¨ ì‚¬ìš©ëŸ‰ ì—¬ë¶€
- `is_notebook`: Notebook ê´€ë ¨ ì‚¬ìš©ëŸ‰ ì—¬ë¶€
- `is_training`: Training ê´€ë ¨ ì‚¬ìš©ëŸ‰ ì—¬ë¶€
- `is_spot`: Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© ì—¬ë¶€
- `usage_hours`: ì‚¬ìš© ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„ì¸ ê²½ìš°)

#### ìƒì„±ë˜ëŠ” ì§‘ê³„ í…Œì´ë¸”
1. **fact_sagemaker_costs**: ì›ì‹œ ë°ì´í„° + íŒŒìƒ ì»¬ëŸ¼
2. **agg_endpoint_hours**: Endpoint ë¦¬ì†ŒìŠ¤ë³„ ì‚¬ìš© ì‹œê°„ ë° ë¹„ìš©
3. **agg_training_cost**: Training ì¸ìŠ¤í„´ìŠ¤ë³„ ë¹„ìš©
4. **agg_notebook_hours**: Notebook ì¸ìŠ¤í„´ìŠ¤ë³„ ì‚¬ìš© ì‹œê°„ ë° ë¹„ìš©
5. **agg_spot_ratio**: Spot vs OnDemand ë¹„ìš© ë¹„ìœ¨
6. **monthly_summary**: ì›”ë³„ ìš”ì•½ í†µê³„

### clean.py - LLM ì •ê·œí™” (ì„ íƒì‚¬í•­)

OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš© íƒ€ì…ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.

#### ê¸°ëŠ¥
- SageMaker ì‚¬ìš© íƒ€ì…ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
- ìºì‹±ì„ í†µí•œ ì„±ëŠ¥ ìµœì í™”
- ê·œì¹™ ê¸°ë°˜ ì •ê·œí™”ë¡œ í´ë°±

#### ì¹´í…Œê³ ë¦¬
- **Endpoint**: ì¶”ë¡ /ì¸í¼ëŸ°ìŠ¤ ê´€ë ¨
- **Notebook**: ê°œë°œ/ì‹¤í—˜ìš© ë…¸íŠ¸ë¶
- **Training**: ëª¨ë¸ í›ˆë ¨ ê´€ë ¨
- **Processing**: ë°ì´í„° ì²˜ë¦¬/ì „ì²˜ë¦¬
- **Other**: ê¸°íƒ€

### store.py - ë°ì´í„° ì €ì¥

ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

#### ì €ì¥ í˜•ì‹
- **Parquet**: ì••ì¶•ëœ ì»¬ëŸ¼ ê¸°ë°˜ í˜•ì‹ (ê¸°ë³¸)
- **CSV**: ê²€ì¦ ë° í˜¸í™˜ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ í˜•ì‹

#### ìƒì„±ë˜ëŠ” íŒŒì¼
- `manifest.json`: ë©”íƒ€ë°ì´í„° ë° íŒŒì¼ ëª©ë¡
- `latest/`: ìµœì‹  ë°ì´í„°ì— ëŒ€í•œ ì‹¬ë³¼ë¦­ ë§í¬

## ğŸ“Š ì¶œë ¥ ë°ì´í„° êµ¬ì¡°

```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ sagemaker_cur_202508.parquet    # ì›ì‹œ ë°ì´í„°
â”‚   â””â”€â”€ sagemaker_cur_202508.csv
â””â”€â”€ processed/
    â””â”€â”€ 202508/
        â”œâ”€â”€ fact_sagemaker_costs.parquet    # ì›ì‹œ + íŒŒìƒ ì»¬ëŸ¼
        â”œâ”€â”€ fact_sagemaker_costs.csv
        â”œâ”€â”€ agg_endpoint_hours.parquet      # Endpoint ì§‘ê³„
        â”œâ”€â”€ agg_endpoint_hours.csv
        â”œâ”€â”€ agg_training_cost.parquet       # Training ì§‘ê³„
        â”œâ”€â”€ agg_training_cost.csv
        â”œâ”€â”€ agg_notebook_hours.parquet      # Notebook ì§‘ê³„
        â”œâ”€â”€ agg_notebook_hours.csv
        â”œâ”€â”€ agg_spot_ratio.parquet          # Spot ë¹„ìœ¨
        â”œâ”€â”€ agg_spot_ratio.csv
        â”œâ”€â”€ monthly_summary.parquet         # ì›”ë³„ ìš”ì•½
        â”œâ”€â”€ monthly_summary.csv
        â””â”€â”€ manifest.json                   # ë©”íƒ€ë°ì´í„°
```

## âš™ï¸ í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ (.env íŒŒì¼)

```env
# Redshift ì—°ê²° ì„¤ì •
REDSHIFT_HOST=your-redshift-cluster.region.redshift.amazonaws.com
REDSHIFT_PORT=5439
REDSHIFT_DB=your_database_name
REDSHIFT_USER=your_username
REDSHIFT_PASSWORD=your_password
REDSHIFT_SSL=true

# CUR í…Œì´ë¸” ì„¤ì •
CUR_TABLE=aws_cost_usage

# ì¶œë ¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR=data
```

### ì„ íƒ í™˜ê²½ë³€ìˆ˜

```env
# LLM ì •ê·œí™” ì„¤ì •
USE_LLM_NORMALIZATION=false
OPENAI_API_KEY=sk-your-openai-api-key
```

## ğŸ”’ ë³´ì•ˆ ë° ì•ˆì „ì„±

### ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
- ETL ë½ìœ¼ë¡œ ë™ì‹œ ì‹¤í–‰ ë°©ì§€ (5ë¶„ íƒ€ì„ì•„ì›ƒ)
- íŒŒì¼ ê¸°ë°˜ ë½ ë©”ì»¤ë‹ˆì¦˜

### ì—ëŸ¬ ì²˜ë¦¬
- ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥
- ì˜ˆì™¸ ë°œìƒ ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
- ë¶€ë¶„ ì‹¤íŒ¨ ì‹œì—ë„ ì•ˆì „í•œ ì¢…ë£Œ

### ë°ì´í„° ê²€ì¦
- ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
- í–‰ ìˆ˜ ë° íŒŒì¼ í¬ê¸° ì •ë³´ í¬í•¨


## ë¡œê·¸ í™•ì¸

```bash
# ìƒì„¸ ë¡œê·¸ í™•ì¸
python -m src.run_etl --billing-ym 202508 --accounts 123456789101 2>&1 | tee etl.log

# íŠ¹ì • ë‹¨ê³„ ë¡œê·¸ í•„í„°ë§
grep "Redshift" etl.log
grep "ë³€í™˜" etl.log
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ì¶”ì¶œ ìµœì í™”
- í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ìµœì†Œí™”
- SageMaker ê´€ë ¨ ë°ì´í„°ë§Œ í•„í„°ë§

### ë³€í™˜ ìµœì í™”
- ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì§‘ê³„

### ì €ì¥ ìµœì í™”
- Parquet í˜•ì‹ìœ¼ë¡œ ì••ì¶• ì €ì¥
- CSVëŠ” ê²€ì¦ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©

## ğŸ”„ API ì‚¬ìš©

ETL ëª¨ë“ˆì„ Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from src.etl import extract_cur_from_redshift, transform_all, write_processed

# ë°ì´í„° ì¶”ì¶œ
df_raw = extract_cur_from_redshift("202508", ["123456789101"])

# ë°ì´í„° ë³€í™˜
dfs_transformed = transform_all(df_raw)

# ë°ì´í„° ì €ì¥
output_paths = get_output_paths("202508")
write_processed(dfs_transformed, "202508", output_paths)
```