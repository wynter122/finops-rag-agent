#!/usr/bin/env python3
"""
SageMaker ë¬¸ì„œ URL ëª©ë¡ ì •ì˜
ë¶„ì„ ë°ì´í„°ì—ì„œ URLì„ ë™ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ê´€ë¦¬
"""

from typing import List, Dict, Any
import json
from pathlib import Path
import re

# AWS SageMaker ë¬¸ì„œ ê¸°ë³¸ URL
SAGEMAKER_BASE_URL = "https://docs.aws.amazon.com/sagemaker/latest/dg/"


def get_urls_by_category(category: str) -> List[str]:
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ URL ëª©ë¡ ë°˜í™˜"""
    categories = get_urls_from_analysis_data_by_category()
    return categories.get(category, [])


def get_urls_from_analysis_data() -> List[str]:
    """data/web_structure/ ë””ë ‰í† ë¦¬ì˜ ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ì—ì„œ URL ì¶”ì¶œ"""
    data_dir = Path(__file__).parent.parent.parent.parent / "data" / "web_structure"
    urls = []
    
    if not data_dir.exists():
        print(f"âš ï¸  ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")
        return urls
    
    # JSON íŒŒì¼ë“¤ ì°¾ê¸°
    json_files = list(data_dir.glob("*.json"))
    
    if not json_files:
        print(f"âš ï¸  ë°ì´í„° ë””ë ‰í† ë¦¬ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return urls
    
    print(f"ğŸ“ ë¶„ì„ ë°ì´í„°ì—ì„œ URL ì¶”ì¶œ ì¤‘... ({len(json_files)}ê°œ íŒŒì¼)")
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # sagemaker_linksì—ì„œ URL ì¶”ì¶œ
            if 'sagemaker_links' in data:
                for link in data['sagemaker_links']:
                    if 'url' in link and link['url']:
                        urls.append(link['url'])
            
            print(f"  âœ… {json_file.name}: {len(data.get('sagemaker_links', []))}ê°œ ë§í¬ ì¶”ì¶œ")
            
        except Exception as e:
            print(f"  âŒ {json_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    # ì¤‘ë³µ ì œê±°
    unique_urls = list(set(urls))
    print(f"ğŸ“Š ì´ {len(unique_urls)}ê°œ ê³ ìœ  URL ì¶”ì¶œ ì™„ë£Œ")
    
    return unique_urls


def get_urls_from_analysis_data_by_category() -> Dict[str, List[str]]:
    """ë¶„ì„ ë°ì´í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ URL ë¶„ë¥˜"""
    urls = get_urls_from_analysis_data()
    
    # URLì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
    categories = {
        "studio": [],
        "notebook": [],
        "training": [],
        "inference": [],
        "autopilot": [],
        "feature_store": [],
        "monitoring": [],
        "pipelines": [],
        "canvas": [],
        "geospatial": [],
        "rstudio": [],
        "hyperpod": [],
        "jupyter": [],
        "security": [],
        "assets": [],
        "algorithms": [],
        "frameworks": [],
        "partner": [],
        "migration": [],
        "other": []
    }
    
    for url in urls:
        url_lower = url.lower()
        
        if 'studio' in url_lower:
            if 'classic' in url_lower:
                categories["studio"].append(url)
            elif 'lab' in url_lower:
                categories["studio"].append(url)
            else:
                categories["studio"].append(url)
        elif 'notebook' in url_lower or 'nbi' in url_lower:
            categories["notebook"].append(url)
        elif 'training' in url_lower:
            categories["training"].append(url)
        elif 'inference' in url_lower:
            categories["inference"].append(url)
        elif 'autopilot' in url_lower:
            categories["autopilot"].append(url)
        elif 'feature-store' in url_lower:
            categories["feature_store"].append(url)
        elif 'monitor' in url_lower:
            categories["monitoring"].append(url)
        elif 'pipeline' in url_lower:
            categories["pipelines"].append(url)
        elif 'canvas' in url_lower:
            categories["canvas"].append(url)
        elif 'geospatial' in url_lower:
            categories["geospatial"].append(url)
        elif 'rstudio' in url_lower:
            categories["rstudio"].append(url)
        elif 'hyperpod' in url_lower:
            categories["hyperpod"].append(url)
        elif 'jupyter' in url_lower:
            categories["jupyter"].append(url)
        elif 'security' in url_lower:
            categories["security"].append(url)
        elif 'assets' in url_lower:
            categories["assets"].append(url)
        elif 'algorithm' in url_lower:
            categories["algorithms"].append(url)
        elif 'framework' in url_lower:
            categories["frameworks"].append(url)
        elif 'partner' in url_lower:
            categories["partner"].append(url)
        elif 'migrate' in url_lower:
            categories["migration"].append(url)
        else:
            categories["other"].append(url)
    
    # ë¹ˆ ì¹´í…Œê³ ë¦¬ ì œê±°
    return {k: v for k, v in categories.items() if v}


def get_combined_urls(limit: int = None) -> List[str]:
    """ë¶„ì„ ë°ì´í„°ì—ì„œ URL ì¶”ì¶œ"""
    analysis_urls = get_urls_from_analysis_data()
    
    # ì¤‘ë³µ ì œê±°
    unique_urls = list(set(analysis_urls))
    
    print(f"ğŸ“Š URL ì¶”ì¶œ ê²°ê³¼:")
    print(f"  - ë¶„ì„ ë°ì´í„° URL: {len(analysis_urls)}ê°œ")
    print(f"  - ì¤‘ë³µ ì œê±° í›„: {len(unique_urls)}ê°œ")
    
    if limit:
        unique_urls = unique_urls[:limit]
    
    return unique_urls


def print_url_summary():
    """URL ëª©ë¡ ìš”ì•½ ì¶œë ¥"""
    print("ğŸ“‹ SageMaker ë¬¸ì„œ URL ëª©ë¡ ìš”ì•½")
    print("=" * 60)
    
    # ë¶„ì„ ë°ì´í„° URL ìš”ì•½
    print("\nğŸ”¹ ë¶„ì„ ë°ì´í„° URL:")
    analysis_categories = get_urls_from_analysis_data_by_category()
    total_analysis = 0
    
    for category, urls in analysis_categories.items():
        print(f"  - {category.replace('_', ' ').title()} ({len(urls)}ê°œ):")
        for url in urls:
            filename = url.split('/')[-1]
            print(f"    * {filename}")
        total_analysis += len(urls)
    
    print(f"  ğŸ“Š ì´ ë¶„ì„ ë°ì´í„° URL: {total_analysis}ê°œ")
    
    # ìµœì¢… URL ìš”ì•½
    print("\nğŸ”¹ ìµœì¢… URL ëª©ë¡:")
    final_urls = get_combined_urls()
    print(f"  ğŸ“Š ì´ URL: {len(final_urls)}ê°œ")


if __name__ == "__main__":
    print_url_summary()
